{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AV_FinalContest_AgeEstimation_Test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZtL8903ncx1"
      },
      "source": [
        "## **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCAOv8YlnjEJ"
      },
      "source": [
        "This notebook has been created for the final contest of Artificial Vision subject at University of Salerno.The aim of this project is to design a DCNN (as regressor or classifier) for age estimation on [VggFace2 dataset](https://github.com/ox-vgg/vgg_face2) labeled with ages by [MiviaLab](https://mivia.unisa.it/).\r\n",
        "\r\n",
        "<br/>\r\n",
        "\r\n",
        "We decided to build a classifier able to recognize 101 classes (ages from 0 to 100), in particular we choose the [Resnet50 model](https://github.com/WeidiXie/Keras-VGGFace2-ResNet50).\r\n",
        "\r\n",
        "In this notebook, we show our **test procedure**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwZgVV9Qn3Uk"
      },
      "source": [
        "## **Initialization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r43c-DaDn58A"
      },
      "source": [
        "First of all, we have to mount the Drive and to go in the folder where all operations has to be done because it contains all the needed files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkOCmLF1nh7P"
      },
      "source": [
        "from google.colab import drive\r\n",
        "import os\r\n",
        "\r\n",
        "drive.mount('/content/drive')\r\n",
        "os.chdir('/content/drive/Shareddrives/ArtificialVision/FinalContest2020')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3wI4xw5n-5j"
      },
      "source": [
        "Check if we are using a GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRtRglHaoAak"
      },
      "source": [
        "%tensorflow_version 2.x\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "device_name = tf.test.gpu_device_name()\r\n",
        "if device_name != '/device:GPU:0':\r\n",
        "  raise SystemError('GPU device not found')\r\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yskwpvNdpeh1"
      },
      "source": [
        "Install MTCNN for face detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eweIV8upcW7"
      },
      "source": [
        "!pip3 install mtcnn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHjk2yh3qyHW"
      },
      "source": [
        "Install progressbar for checking progress in predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVx0asBlqtph"
      },
      "source": [
        "!pip install progressbar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh8xG5RAoDoP"
      },
      "source": [
        "## Load previously trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piyDG8Stovtw"
      },
      "source": [
        "log_dir = \"./logs/resnet50/\"\r\n",
        "model_path = log_dir+\"/model/resnet50_25epochs.h5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7imBdA9GqAUj"
      },
      "source": [
        "from keras.models import load_model\r\n",
        "\r\n",
        "print(\"Model loading...\")\r\n",
        "model = load_model(model_path)\r\n",
        "print(\"Model loading...DONE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQitcKTBpBAr"
      },
      "source": [
        "## Recover last saved weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cl_BhN5pEsX"
      },
      "source": [
        "def _find_latest_checkpoint(d):\r\n",
        "    all_checks = glob(os.path.join(d, '*'))\r\n",
        "    max_ep = 0\r\n",
        "    max_c = None\r\n",
        "    for c in all_checks:\r\n",
        "        epoch_num = re.search(ep_re, c)\r\n",
        "        if epoch_num is not None:\r\n",
        "            epoch_num = int(epoch_num.groups(1)[0])\r\n",
        "            if epoch_num > max_ep:\r\n",
        "                max_ep = epoch_num\r\n",
        "                max_c = c\r\n",
        "    return max_ep, max_c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlxOfALFqVm-"
      },
      "source": [
        "from glob import glob\r\n",
        "import re\r\n",
        "\r\n",
        "dirnm = \"training_logs/\"\r\n",
        "dirnm = os.path.join(log_dir, dirnm) #./logs/<net>/inference-training/\r\n",
        "print(\"Log dir: {}\".format(dirnm))\r\n",
        "if not os.path.isdir(dirnm): os.mkdir(dirnm)\r\n",
        "\r\n",
        "chk_dir = dirnm + \"weights/\" #./logs/<net>/inference-training/weights/\r\n",
        "print(\"Checkpoint dir: {}\".format(chk_dir))\r\n",
        "if not os.path.isdir(chk_dir): os.mkdir(chk_dir)\r\n",
        "\r\n",
        "filepath = os.path.join(chk_dir, \"checkpoint.{epoch:02d}.h5\")\r\n",
        "ep_re = re.compile('checkpoint.([0-9]+).h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-EksF3_p71f"
      },
      "source": [
        "test_epoch, _ = _find_latest_checkpoint(chk_dir)\r\n",
        "print(\"Using epoch %d\" % test_epoch)\r\n",
        "\r\n",
        "print(\"Weights loading...\")\r\n",
        "model.load_weights(filepath.format(epoch=int(test_epoch)))\r\n",
        "print(\"Weights loading...DONE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv1XyeCfpK7p"
      },
      "source": [
        "## Do face extraction (we used annotation provided by MiviaLab)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2XSD49jpSJ_"
      },
      "source": [
        "def extract_face(img):\r\n",
        "  if img is not None:\r\n",
        "    detector = MTCNN()\r\n",
        "    # detect all faces presented in the image\r\n",
        "    results = detector.detect_faces(img)\r\n",
        "    # compute max detected area for choosing face in close-up\r\n",
        "    max_area = 0\r\n",
        "    index = 0 \r\n",
        "    if len(results) == 0: #if no faces are detected, return original image\r\n",
        "      return img\r\n",
        "    else:\r\n",
        "      for i in range(0, len(results)):\r\n",
        "        x1, y1, width, height = results[i]['box']\r\n",
        "        area = width*height\r\n",
        "        if area>=max_area:\r\n",
        "          max_area = area\r\n",
        "          index = i\r\n",
        "\r\n",
        "      # crop faces using parameters of max detected area\r\n",
        "      x_o, y_o, width, height = results[index]['box']\r\n",
        "      if width >= 10 and height >= 10: #if detected area too small, return original image\r\n",
        "        # check if top-left point is negative, that means faces outside limits of image\r\n",
        "        if x_o >= 0:\r\n",
        "          x_o = 0\r\n",
        "        if y_o >=0:\r\n",
        "          y_o = 0\r\n",
        "        # crop\r\n",
        "        x1, y1 = x_o, y_o\r\n",
        "        x2, y2 = x_o + width, y_o+height\r\n",
        "        face = img[y1:y2, x1:x2]\r\n",
        "        return face\r\n",
        "      else:\r\n",
        "        return img\r\n",
        "  else:\r\n",
        "    print(\"Image {} not found\".format(img))\r\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL9dC3n-pi03"
      },
      "source": [
        "## Utility function for reads image from TFRecord"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCTkhN43pnbx"
      },
      "source": [
        "def decode_image(image):\r\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\r\n",
        "  #image = tf.cast(image, tf.float32)        \r\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h7ZI4VspoTs"
      },
      "source": [
        "## Dataset creation from TFRecord file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nnjuN5IpvTA"
      },
      "source": [
        "%tensorflow_version 2.x\r\n",
        "import tensorflow as tf\r\n",
        "from functools import partial\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "def read_tfrecord_test(example):\r\n",
        "    tfrecord_format = (\r\n",
        "        {\r\n",
        "          'path': tf.io.FixedLenFeature([], tf.string),\r\n",
        "          'image_raw': tf.io.FixedLenFeature([], tf.string),\r\n",
        "        }\r\n",
        "    )    \r\n",
        "    return tf.io.parse_single_example(example, tfrecord_format)\r\n",
        "    \r\n",
        "def read_tfrecord(example):\r\n",
        "    tfrecord_format = (\r\n",
        "        {\r\n",
        "          'path': tf.io.FixedLenFeature([], tf.string),\r\n",
        "          'height': tf.io.FixedLenFeature([], tf.int64),\r\n",
        "          'width': tf.io.FixedLenFeature([], tf.int64),\r\n",
        "          'label': tf.io.FixedLenFeature([], tf.int64),\r\n",
        "          'image_raw': tf.io.FixedLenFeature([], tf.string),\r\n",
        "        }\r\n",
        "    )\r\n",
        "    return tf.io.parse_single_example(example, tfrecord_format)\r\n",
        "\r\n",
        "def load_dataset(filenames, test):\r\n",
        "    ignore_order = tf.data.Options()\r\n",
        "    ignore_order.experimental_deterministic = False\r\n",
        "    dataset = tf.data.TFRecordDataset(filenames) # create dataset from path passed as input\r\n",
        "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\r\n",
        "    \r\n",
        "    # read dataset records according to its type (test or not)\r\n",
        "    if not test:\r\n",
        "      dataset = dataset.map(partial(read_tfrecord))\r\n",
        "    else:\r\n",
        "      dataset = dataset.map(partial(read_tfrecord_test))\r\n",
        "    return dataset\r\n",
        "\r\n",
        "def get_dataset(filenames, dataset_dim, test=False):\r\n",
        "    dataset = load_dataset(filenames, test) \r\n",
        "    if not test: #shuffle elements at each epoch\r\n",
        "      dataset = dataset.shuffle(dataset_dim//256, reshuffle_each_iteration=True).repeat()\r\n",
        "    #This allows later elements to be prepared while the current element is being processed.\r\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE) \r\n",
        "    if not test: # set batch size\r\n",
        "      dataset = dataset.batch(batch_size)\r\n",
        "    return dataset\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_aofq2OrlYK"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50emgGowqlnE"
      },
      "source": [
        "PATH_TO_TFR = \"./tfrecords/own_test_set_cropped.record\"\r\n",
        "\r\n",
        "TOT_TEST_SAMPLE = 126179"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMmR9Glhpz4N"
      },
      "source": [
        "import progressbar\r\n",
        "import csv\r\n",
        "\r\n",
        "x_test = []\r\n",
        "\r\n",
        "model_name = log_dir.split('/')[-2]\r\n",
        "PATH_TO_CSV_PRED = './tfrecords/annotations/own_test_set_predictions_{}.csv'.format(model_name) #GROUP18.csv\r\n",
        "\r\n",
        "print (\"Testing {} on {} - {} samples\".format(model_name,PATH_TO_TFR,TOT_TEST_SAMPLE))\r\n",
        "\r\n",
        "# create dataset iterator\r\n",
        "test_dataset = get_dataset(PATH_TO_TFR, TOT_TEST_SAMPLE, test=True)\r\n",
        "test_generator = iter(test_dataset)\r\n",
        "\r\n",
        "MAX_VALUE = TOT_TEST_SAMPLE\r\n",
        "\r\n",
        "print(\"Writing predictions to {} ...\".format(PATH_TO_CSV_PRED))\r\n",
        "with progressbar.ProgressBar(max_value=MAX_VALUE) as bar:\r\n",
        "  with open(PATH_TO_CSV_PRED, mode='w', newline=\"\", encoding=\"utf-8\") as csvfile:\r\n",
        "    csv_writer = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\r\n",
        "    for j in range(0, TOT_TEST_SAMPLE):\r\n",
        "      try:\r\n",
        "        #take a single elem of TFRecord (path+image)\r\n",
        "        parsing_dict = test_generator.get_next() \r\n",
        "        #read each image-label of the batch\r\n",
        "        path = parsing_dict[\"path\"].numpy().decode('utf-8')\r\n",
        "        jpg = (decode_image(parsing_dict[\"image_raw\"])).numpy()\r\n",
        "        jpg = np.reshape(jpg, [1,jpg.shape[0], jpg.shape[1], jpg.shape[2]])\r\n",
        "        # do prediction\r\n",
        "        pred = np.argmax(model.predict(jpg))\r\n",
        "        # write prediction to CSV file\r\n",
        "        csv_writer.writerow([path,int(pred)])\r\n",
        "        bar.update(j+1)\r\n",
        "      except tf.errors.OutOfRangeError:\r\n",
        "        print(\"Iterator exhausted\\n\")\r\n",
        "print(\"Writing predictions to {} ... DONE\".format(PATH_TO_CSV_PRED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZLvCWbKro0i"
      },
      "source": [
        "## Compute MAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASX2He3nrioL"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\r\n",
        "import csv\r\n",
        "\r\n",
        "y_pred = []\r\n",
        "y_true = []\r\n",
        "\r\n",
        "def compute_mae(gt_path, pred_path):\r\n",
        "  with open(gt_path) as csvfile_gt:\r\n",
        "    with open(pred_path) as csvfile_pred:\r\n",
        "      csvreader_gt = csv.reader(csvfile_gt, delimiter=',')\r\n",
        "      csvreader_pred = csv.reader(csvfile_pred, delimiter=',')\r\n",
        "      for row in csvreader_gt:\r\n",
        "        if len(row)!=0:\r\n",
        "          val = row[1]\r\n",
        "          y_true.append(float(val))\r\n",
        "      for row in csvreader_pred:\r\n",
        "        if len(row)!=0:\r\n",
        "          val = row[1]\r\n",
        "          y_pred.append(float(val))\r\n",
        "  \r\n",
        "  print(\"MAE:{}\".format(mean_absolute_error(y_true, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMAxNmoYrwVK"
      },
      "source": [
        "PATH_TO_CSV_GT = \"./tfrecords/annotations/own_test_set_gt.csv\"\r\n",
        "PATH_TO_CSV_PRED = \"./tfrecords/annotations/own_test_set_predictions_xception.csv\"\r\n",
        "\r\n",
        "compute_mae(PATH_TO_CSV_GT, PATH_TO_CSV_PRED)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}